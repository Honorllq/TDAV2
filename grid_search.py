#!/usr/bin/env python
"""
ç½‘æ ¼æœç´¢è„šæœ¬ - è‡ªåŠ¨æ‰¾åˆ°TDA+GR-CLIPçš„æœ€ä¼˜è¶…å‚æ•°

ä½¿ç”¨æ–¹æ³•:
    # å¿«é€Ÿæœç´¢ (æ¨è)
    python grid_search.py --dataset caltech101 --backbone ViT-B/16 --mode quick

    # åªæœç´¢GR-CLIPå‚æ•°
    python grid_search.py --mode grclip_only

    # åªæœç´¢TDAå‚æ•°
    python grid_search.py --mode tda_only

    # å®Œæ•´æœç´¢ (è€—æ—¶é•¿)
    python grid_search.py --mode full

è¾“å‡º:
    - results/grid_search_YYYYMMDD_HHMMSS/results_final.csv: æ‰€æœ‰å®éªŒç»“æœ
    - results/grid_search_YYYYMMDD_HHMMSS/best_config.txt: æœ€ä¼˜é…ç½®
"""

import os
import sys
import argparse
import itertools
from datetime import datetime
from pathlib import Path
import pandas as pd
import random
import torch
import clip
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from utils import *
from runner import update_cache, compute_cache_logits, build_visual_prototypes, compute_modality_means, calibrate_with_gr_clip


def run_single_experiment(config, dataset_name, data_root, clip_model, clip_weights, preprocess):
    """
    è¿è¡Œå•æ¬¡å®éªŒ

    Args:
        config: é…ç½®å­—å…¸
        dataset_name: æ•°æ®é›†åç§°
        data_root: æ•°æ®é›†æ ¹ç›®å½•
        clip_model: CLIPæ¨¡å‹
        clip_weights: CLIPæ–‡æœ¬æƒé‡
        preprocess: é¢„å¤„ç†å‡½æ•°

    Returns:
        accuracy: æµ‹è¯•å‡†ç¡®ç‡
    """
    # æ„å»ºæ•°æ®åŠ è½½å™¨
    test_loader, _, _ = build_test_data_loader(dataset_name, data_root, preprocess)

    with torch.no_grad():
        pos_cache, neg_cache, accuracies = {}, {}, []

        # æå–é…ç½®
        pos_cfg = config['positive']
        neg_cfg = config['negative']
        cal_cfg = config['calibrate']

        text_mean, image_mean = None, None
        calibrated_weights = clip_weights

        for i, (images, target) in enumerate(tqdm(test_loader, desc='æµ‹è¯•è¿›åº¦', leave=False)):
            # æ­¥éª¤1: ç‰¹å¾æå–
            image_features, clip_logits, loss, prob_map, pred = get_clip_logits(images, clip_model, clip_weights)
            target = target.cuda()
            prop_entropy = get_entropy(loss, clip_weights)

            # æ­¥éª¤2: æ›´æ–°æ­£ç¼“å­˜
            if pos_cfg['enabled']:
                update_cache(pos_cache, pred, [image_features, loss], pos_cfg['shot_capacity'])

            # æ­¥éª¤3: æ›´æ–°è´Ÿç¼“å­˜
            if neg_cfg['enabled']:
                if neg_cfg['entropy_threshold']['lower'] < prop_entropy < neg_cfg['entropy_threshold']['upper']:
                    update_cache(neg_cache, pred, [image_features, loss, prob_map],
                               neg_cfg['shot_capacity'], True)

            # æ­¥éª¤4: GR-CLIPæ ¡å‡†
            if cal_cfg['enabled'] and len(pos_cache) >= cal_cfg['min_cache_size']:
                if i % cal_cfg['update_interval'] == 0:
                    text_mean, image_mean = compute_modality_means(pos_cache, clip_weights)
                    visual_prototypes = build_visual_prototypes(pos_cache)
                    calibrated_weights = calibrate_with_gr_clip(
                        visual_prototypes, clip_weights, text_mean, image_mean,
                        alpha=cal_cfg['fusion_alpha']
                    )

            # æ­¥éª¤5: è®¡ç®—é¢„æµ‹
            clip_baseline_logits = 100.0 * image_features @ clip_weights

            if text_mean is not None and image_mean is not None and cal_cfg['enabled']:
                # è‡ªé€‚åº”GR-CLIP
                clip_confidence = clip_baseline_logits.softmax(1).max().item()
                if clip_confidence < cal_cfg.get('confidence_threshold', 1.0):
                    image_features_centered = image_features - image_mean.unsqueeze(0)
                    image_features_centered = image_features_centered / image_features_centered.norm(dim=1, keepdim=True)
                    gr_clip_logits = 100.0 * image_features_centered @ calibrated_weights
                else:
                    gr_clip_logits = clip_baseline_logits
            else:
                gr_clip_logits = clip_baseline_logits

            # æ­¥éª¤6: TDAç¼“å­˜
            tda_logits = torch.zeros_like(gr_clip_logits)
            if pos_cfg['enabled'] and pos_cache:
                tda_logits += compute_cache_logits(image_features, pos_cache,
                                                   pos_cfg['alpha'], pos_cfg['beta'], clip_weights)
            if neg_cfg['enabled'] and neg_cache:
                tda_logits -= compute_cache_logits(image_features, neg_cache,
                                                   neg_cfg['alpha'], neg_cfg['beta'], clip_weights,
                                                   (neg_cfg['mask_threshold']['lower'],
                                                    neg_cfg['mask_threshold']['upper']))

            # æ­¥éª¤7: èåˆé¢„æµ‹
            final_logits = gr_clip_logits + tda_logits

            # è¯„ä¼°
            acc = cls_acc(final_logits, target)
            accuracies.append(acc)

        avg_acc = sum(accuracies) / len(accuracies)
        return avg_acc


def grid_search(args, search_space):
    """æ‰§è¡Œç½‘æ ¼æœç´¢"""

    # åˆ›å»ºç»“æœç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_dir = Path("results") / f"grid_search_{timestamp}"
    result_dir.mkdir(parents=True, exist_ok=True)

    print(f"\n{'='*80}")
    print(f"ğŸ” TDA+GR-CLIP ç½‘æ ¼æœç´¢")
    print(f"{'='*80}")
    print(f"ğŸ“ ç»“æœç›®å½•: {result_dir}")
    print(f"ğŸ¯ æ•°æ®é›†: {args.dataset}")
    print(f"ğŸ§  Backbone: {args.backbone}")
    print(f"ğŸ”§ æœç´¢æ¨¡å¼: {args.mode}")

    # åˆå§‹åŒ–CLIPæ¨¡å‹
    print(f"\nğŸ“¥ åŠ è½½CLIPæ¨¡å‹...")
    clip_model, preprocess = clip.load(args.backbone)
    clip_model.eval()

    # è®¾ç½®éšæœºç§å­
    random.seed(1)
    torch.manual_seed(1)

    # åŠ è½½æ•°æ®é›†å’Œæ–‡æœ¬ç‰¹å¾
    print(f"ğŸ“¥ åŠ è½½æ•°æ®é›†å’Œæ–‡æœ¬ç‰¹å¾...")
    from utils import get_config_file, build_test_data_loader, clip_classifier
    cfg = get_config_file(args.config_dir, args.dataset)
    test_loader, classnames, template = build_test_data_loader(args.dataset, args.data_root, preprocess)
    clip_weights = clip_classifier(classnames, template, clip_model)

    # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
    param_names = list(search_space.keys())
    param_values = list(search_space.values())
    all_combinations = list(itertools.product(*param_values))

    total_exps = len(all_combinations)
    print(f"ğŸ“Š æ€»å®éªŒæ•°: {total_exps}")
    print(f"{'='*80}\n")

    # åŸºç¡€é…ç½®
    base_config = {
        'positive': {
            'enabled': True,
            'shot_capacity': 3,
            'alpha': 2.0,
            'beta': 5.0
        },
        'negative': {
            'enabled': True,
            'shot_capacity': 2,
            'alpha': 0.117,
            'beta': 1.0,
            'entropy_threshold': {'lower': 0.2, 'upper': 0.5},
            'mask_threshold': {'lower': 0.03, 'upper': 1.0}
        },
        'calibrate': {
            'enabled': True,
            'min_cache_size': 20,
            'update_interval': 100,
            'fusion_alpha': 0.8,
            'confidence_threshold': 0.7
        }
    }

    # å­˜å‚¨ç»“æœ
    results = []
    best_acc = 0
    best_params = None
    best_config = None

    # éå†æ‰€æœ‰ç»„åˆ
    for exp_id, combination in enumerate(all_combinations, 1):
        params = dict(zip(param_names, combination))

        print(f"\n{'â”€'*80}")
        print(f"ğŸ§ª å®éªŒ {exp_id}/{total_exps}")
        print(f"{'â”€'*80}")

        # åˆ›å»ºå½“å‰é…ç½®
        config = {
            'positive': base_config['positive'].copy(),
            'negative': base_config['negative'].copy(),
            'calibrate': base_config['calibrate'].copy()
        }

        # æ›´æ–°å‚æ•°
        for key, value in params.items():
            if key.startswith('pos_'):
                config['positive'][key.replace('pos_', '')] = value
            elif key.startswith('neg_'):
                config['negative'][key.replace('neg_', '')] = value
            elif key.startswith('cal_'):
                config['calibrate'][key.replace('cal_', '')] = value

        # æ‰“å°å½“å‰é…ç½®
        print(f"é…ç½®:")
        for k, v in params.items():
            print(f"  {k}: {v}")

        # è¿è¡Œå®éªŒ
        try:
            accuracy = run_single_experiment(
                config, args.dataset, args.data_root, clip_model, clip_weights, preprocess
            )
            print(f"âœ… å‡†ç¡®ç‡: {accuracy:.2f}%")

            # è®°å½•ç»“æœ
            result = params.copy()
            result['accuracy'] = accuracy
            result['exp_id'] = exp_id
            results.append(result)

            # æ›´æ–°æœ€ä½³ç»“æœ
            if accuracy > best_acc:
                best_acc = accuracy
                best_params = params.copy()
                best_config = config
                print(f"ğŸŒŸ æ–°çš„æœ€ä½³ç»“æœ! {best_acc:.2f}%")

        except Exception as e:
            print(f"âŒ å®éªŒå¤±è´¥: {e}")
            result = params.copy()
            result['accuracy'] = None
            result['exp_id'] = exp_id
            result['error'] = str(e)
            results.append(result)

        # ä¿å­˜ä¸­é—´ç»“æœ
        df = pd.DataFrame(results)
        df.to_csv(result_dir / "results_partial.csv", index=False)

    # ä¿å­˜æœ€ç»ˆç»“æœ
    df = pd.DataFrame(results)
    df = df.sort_values('accuracy', ascending=False)
    csv_path = result_dir / "results_final.csv"
    df.to_csv(csv_path, index=False)

    print(f"\n{'='*80}")
    print(f"âœ¨ ç½‘æ ¼æœç´¢å®Œæˆ!")
    print(f"{'='*80}")
    print(f"ğŸ“Š ç»“æœå·²ä¿å­˜: {csv_path}")
    print(f"\nğŸ† æœ€ä½³é…ç½®:")
    print(f"   å‡†ç¡®ç‡: {best_acc:.2f}%")
    for k, v in best_params.items():
        print(f"   {k}: {v}")

    # ä¿å­˜æœ€ä½³é…ç½®
    if best_config:
        config_path = result_dir / "best_config.txt"
        with open(config_path, 'w', encoding='utf-8') as f:
            f.write(f"Best Accuracy: {best_acc:.2f}%\n\n")
            f.write("Best Configuration:\n")
            f.write(f"{best_config}\n\n")
            f.write("YAML Format:\n")
            f.write(f"positive:\n")
            for k, v in best_config['positive'].items():
                f.write(f"  {k}: {v}\n")
            f.write(f"\nnegative:\n")
            for k, v in best_config['negative'].items():
                f.write(f"  {k}: {v}\n")
            f.write(f"\ncalibrate:\n")
            for k, v in best_config['calibrate'].items():
                f.write(f"  {k}: {v}\n")

        print(f"ğŸ’¾ æœ€ä½³é…ç½®å·²ä¿å­˜: {config_path}")

    print(f"{'='*80}\n")

    # æ‰“å°Top 5
    print("\nğŸ… Top 5 é…ç½®:")
    print(df.head(5).to_string(index=False))

    return df, best_params, best_acc


def get_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='TDA+GR-CLIP ç½‘æ ¼æœç´¢')
    parser.add_argument('--dataset', type=str, default='caltech101',
                        help='æ•°æ®é›†åç§° (default: caltech101)')
    parser.add_argument('--backbone', type=str, default='ViT-B/16',
                        choices=['RN50', 'ViT-B/16'],
                        help='CLIP backbone (default: ViT-B/16)')
    parser.add_argument('--config-dir', type=str, default='configs',
                        help='é…ç½®ç›®å½• (default: configs)')
    parser.add_argument('--data-root', type=str,
                        default='E:/ç ”ç©¶ç”Ÿ/æå‰è¿›ç»„/æç¤ºå­¦ä¹ æ–¹å‘/code/dataset/',
                        help='æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--mode', type=str, default='quick',
                        choices=['quick', 'full', 'grclip_only', 'tda_only'],
                        help='æœç´¢æ¨¡å¼ (default: quick)')
    return parser.parse_args()


def main():
    args = get_args()

    # å®šä¹‰æœç´¢ç©ºé—´
    if args.mode == 'quick':
        # å¿«é€Ÿæœç´¢: åªæœç´¢æœ€å…³é”®å‚æ•°
        search_space = {
            'pos_alpha': [1.5, 2.0, 2.5],           # TDAæ­£ç¼“å­˜æƒé‡
            'cal_enabled': [True, False],           # æ˜¯å¦å¯ç”¨GR-CLIP
            'cal_fusion_alpha': [0.8, 0.9],        # GR-CLIPèåˆæƒé‡
        }

    elif args.mode == 'grclip_only':
        # åªæœç´¢GR-CLIPå‚æ•°
        search_space = {
            'cal_enabled': [True],
            'cal_fusion_alpha': [0.3, 0.5, 0.7, 0.8, 0.9],
            'cal_confidence_threshold': [0.6, 0.7, 0.8, 0.9],
            'cal_min_cache_size': [10, 20, 30],
        }

    elif args.mode == 'tda_only':
        # åªæœç´¢TDAå‚æ•° (ç¦ç”¨GR-CLIP)
        search_space = {
            'pos_shot_capacity': [2, 3, 4],
            'pos_alpha': [1.0, 1.5, 2.0, 2.5, 3.0],
            'pos_beta': [4.0, 5.0, 6.0],
            'neg_alpha': [0.1, 0.117, 0.15],
            'cal_enabled': [False],
        }

    elif args.mode == 'full':
        # å®Œæ•´æœç´¢ (éå¸¸è€—æ—¶!)
        search_space = {
            'pos_shot_capacity': [2, 3, 4],
            'pos_alpha': [1.5, 2.0, 2.5],
            'pos_beta': [4.0, 5.0, 6.0],
            'neg_alpha': [0.1, 0.117],
            'cal_enabled': [True, False],
            'cal_fusion_alpha': [0.7, 0.8, 0.9],
            'cal_confidence_threshold': [0.6, 0.7, 0.8],
        }

    # æ‰§è¡Œç½‘æ ¼æœç´¢
    grid_search(args, search_space)


if __name__ == "__main__":
    main()
